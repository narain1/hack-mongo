version: '3.8'

services:
  llm-api:
    build: ./llm
    container_name: llm-api
    restart: unless-stopped
    environment:
      - MODEL_TYPE=mock
      - MODEL_NAME=mock-llm-v1
      # Add your model-specific environment variables here:
      # - OPENAI_API_KEY=${OPENAI_API_KEY}
      # - HF_TOKEN=${HF_TOKEN}
      # - MODEL_PATH=/models/your-model
    ports:
      - "8000:8000"
    networks:
      - tunnel-net
    # volumes:
    #   # Mount for local models (uncomment if using local models)
    #   - ./models:/models:ro
    #   # Mount for persistent data
    #   - llm-data:/app/data

  cloudflared:
    image: cloudflare/cloudflared:latest
    container_name: cloudflared-llm
    command: tunnel --no-autoupdate run --token ${CLOUDFLARE_TUNNEL_TOKEN}
    restart: unless-stopped
    networks:
      - tunnel-net
    depends_on:
      - llm-api
    environment:
      - TUNNEL_TOKEN=${CLOUDFLARE_TUNNEL_TOKEN}

networks:
  tunnel-net:
    driver: bridge

# volumes:
#   llm-data:
#     driver: local